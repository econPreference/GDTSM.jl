var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = TermStructureModels\nDocTestSetup  = quote\n    using TermStructureModels\nend","category":"page"},{"location":"api/#API-documentation","page":"API","title":"API documentation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Pages = [\"api.md\"]","category":"page"},{"location":"api/#Exported-Functions","page":"API","title":"Exported Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [TermStructureModels]\nPrivate = false","category":"page"},{"location":"api/#TermStructureModels.Forecast","page":"API","title":"TermStructureModels.Forecast","text":"@kwdef struct Forecast <: PosteriorSample\n\nIt contains a result of the scenario analysis, the conditional prediction for yields, factors = [PCs macros], and term premiums.\n\nyields\nfactors\nTP: term premium forecasts\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.Hyperparameter","page":"API","title":"TermStructureModels.Hyperparameter","text":"@kwdef struct Hyperparameter\n\np::Int\nq::Matrix\nν0\nΩ0::Vector\nμϕ_const::Vector = zeros(length(Ω0)): It is a prior mean of a constant term in our VAR.\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.LatentSpace","page":"API","title":"TermStructureModels.LatentSpace","text":"@kwdef struct LatentSpace <: PosteriorSample\n\nWhen the model goes to the JSZ latent factor space, the statistical parameters in struct Parameter are also transformed. This struct contains the transformed parameters. Specifically, the transformation is latents[t,:] = T0P_ + inv(T1X)*PCs[t,:]. \n\nIn the latent factor space, the transition equation is data[t,:] = KₚXF + GₚXFXF*vec(data[t-1:-1:t-p,:]') + MvNormal(O,ΩXFXF), where data = [latent macros].\n\nlatents::Matrix\nκQ\nkQ_infty\nKₚXF::Vector\nGₚXFXF::Matrix\nΩXFXF::Matrix\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.Parameter","page":"API","title":"TermStructureModels.Parameter","text":"@kwdef struct Parameter <: PosteriorSample\n\nIt contains statistical parameters of the model that are sampled from function posterior_sampler.\n\nκQ::Float64\nkQ_infty::Float64\nϕ::Matrix{Float64}\nσ²FF::Vector{Float64}\nΣₒ::Vector{Float64}\nγ::Vector{Float64}\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.PosteriorSample","page":"API","title":"TermStructureModels.PosteriorSample","text":"abstract type PosteriorSample\n\nIt is a super-set of structs Parameter, ReducedForm, LatentSpace, YieldCurve, TermPremium, Forecast.\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.ReducedForm","page":"API","title":"TermStructureModels.ReducedForm","text":"@kwdef struct ReducedForm <: PosteriorSample\n\nIt contains statistical parameters in terms of the reduced form VAR(p) in P-dynamics. λP and ΛPF are parameters in the market prices of risks equation, and they only contain the first dQ non-zero equations. \n\nκQ\nkQ_infty\nKₚF\nGₚFF\nΩFF::Matrix\nΣₒ::Vector\nλP\nΛPF\nmpr::Matrix(market prices of risks, T, dP)\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.Scenario","page":"API","title":"TermStructureModels.Scenario","text":"@kwdef struct Scenario\n\nIt contains scenarios to be conditioned in the scenario analysis. When y = [yields; macros] is a observed vector in our measurement equation, Scenario.combinations*y = Scenario.values constitutes the scenario at a specific time. Vector{Scenario} is used to describe a time-series of scenarios.\n\ncombinations and values should be Matrix and Vector. If values is a scalar, combinations would be a matrix with one raw vector and values should be one-dimensional vector, for example [values]. \n\ncombinations::Matrix\nvalues::Vector\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.TermPremium","page":"API","title":"TermStructureModels.TermPremium","text":"@kwdef struct TermPremium <: PosteriorSample\n\nIt contains a estimated time series of a term premium for one maturity.\n\nTP::Vector: term premium estimates of a specific maturity bond. TP = timevarying_TP + const_TP + jensen holds.\ntimevarying_TP::Matrix: rows:time, cols:factors, values: contributions of factors on TP\nconst_TP::Float64: constant part in TP\njensen::Float64: the part due to the Jensen's inequality\n\n\n\n\n\n","category":"type"},{"location":"api/#TermStructureModels.YieldCurve","page":"API","title":"TermStructureModels.YieldCurve","text":"@kwdef struct YieldCurve <: PosteriorSample\n\nIt contains a fitted yield curve. yields[t,:] = intercept + slope*latents[t,:] holds.\n\nlatents::Matrix: latent pricing factors in LatentSpace\nyields\nintercept\nslope\n\n\n\n\n\n","category":"type"},{"location":"api/#Base.getindex-Tuple{PosteriorSample, Symbol}","page":"API","title":"Base.getindex","text":"getindex(x::PosteriorSample, c::Symbol)\n\nFor struct <: PosteriorSample, struct[:name] calls objects in struct.\n\n\n\n\n\n","category":"method"},{"location":"api/#Base.getindex-Tuple{Vector{var\"#s13\"} where var\"#s13\"<:PosteriorSample, Symbol}","page":"API","title":"Base.getindex","text":"getindex(x::Vector{<:PosteriorSample}, c::Symbol)\n\nFor struct <: PosteriorSample, struct[:name] calls objects in struct. Output[i] = ith posterior sample\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.mean-Tuple{Vector{var\"#s12\"} where var\"#s12\"<:PosteriorSample}","page":"API","title":"Statistics.mean","text":"mean(x::Vector{<:PosteriorSample})\n\nOutput[:variable name] returns the corresponding posterior mean.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.median-Tuple{Vector{var\"#s7\"} where var\"#s7\"<:PosteriorSample}","page":"API","title":"Statistics.median","text":"median(x::Vector{<:PosteriorSample})\n\nOutput[:variable name] returns the corresponding posterior median.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.quantile-Tuple{Vector{var\"#s7\"} where var\"#s7\"<:PosteriorSample, Any}","page":"API","title":"Statistics.quantile","text":"quantile(x::Vector{<:PosteriorSample}, q)\n\nOutput[:variable name] returns a quantile of the corresponding posterior distribution.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.std-Tuple{Vector{var\"#s12\"} where var\"#s12\"<:PosteriorSample}","page":"API","title":"Statistics.std","text":"std(x::Vector{<:PosteriorSample})\n\nOutput[:variable name] returns the corresponding posterior standard deviation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.var-Tuple{Vector{var\"#s12\"} where var\"#s12\"<:PosteriorSample}","page":"API","title":"Statistics.var","text":"var(x::Vector{<:PosteriorSample})\n\nOutput[:variable name] returns the corresponding posterior variance.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.AR_res_var-Tuple{Vector{T} where T, Any}","page":"API","title":"TermStructureModels.AR_res_var","text":"AR_res_var(TS::Vector, p)\n\nIt derives an MLE error variance estimate of an AR(p) model\n\nInput\n\nunivariate time series TS and the lag p\n\noutput(2)\n\nresidual variance estimate, AR(p) coefficients\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.GQ_XX-Tuple{}","page":"API","title":"TermStructureModels.GQ_XX","text":"GQ_XX(; κQ)\n\nκQ governs a conditional mean of the Q-dynamics of X, and its slope matrix has a restricted form. This function shows that restricted form.\n\nOutput\n\nslope matrix of the Q-conditional mean of X\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.LDL-Tuple{Any}","page":"API","title":"TermStructureModels.LDL","text":"LDL(X)\n\nThis function generate a matrix decomposition, called LDLt. X = L*D*L', where L is a lower triangular matrix and D is a diagonal. How to conduct it can be found at Wikipedia.\n\nInput\n\nDecomposed Object, X\n\nOutput(2)\n\nL, D\n\nDecomposed result is X = L*D*L'\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.PCA","page":"API","title":"TermStructureModels.PCA","text":"PCA(yields, p, proxies=[]; rescaling=false)\n\nIt derives the principal components from yields.\n\nInput\n\nyields[p+1:end, :] is used to construct the affine transformation, and then all yields[:,:] are transformed into the principal components.\nSince signs of PCs is not identified, we use proxies to identify the signs. We flip PCs to make cor(proxies[:, i]. PCs[:,i]) > 0. If proxies is not given, we use the following proxies as a default: [yields[:, end] yields[:, end] - yields[:, 1] 2yields[:, Int(floor(size(yields, 2) / 3))] - yields[:, 1] - yields[:, end]].\nsize(proxies) = (size(yields[p+1:end, :], 1), dQ)\nIf rescaling == true, all PCs and OCs are normalized to have an average std of yields.\n\nOutput(4)\n\nPCs, OCs, Wₚ, Wₒ, mean_PCs\n\nPCs, OCs: first dQ and the remaining principal components\nWₚ, Wₒ: the rotation matrix for PCs and OCs, respectively\nmean_PCs: the mean of PCs before demeaned.\nPCs are demeaned.\n\n\n\n\n\n","category":"function"},{"location":"api/#TermStructureModels.calibrate_μϕ_const-NTuple{7, Any}","page":"API","title":"TermStructureModels.calibrate_μϕ_const","text":"calibrate_μϕ_const(μkQ_infty, σkQ_infty, ν0, yields, macros, τₙ, p; μϕ_const_PCs=[], medium_τ=collect(30:2:48), iteration=1000, data_scale=1200, medium_τ_pr=[], τ=[])\n\nThe purpose of the function is to calibrate a prior mean of the first dQ constant terms in our VAR. Adjust your prior setting based on the prior samples in outputs.\n\nInput\n\nμϕ_const_PCs is your prior mean of the first dQ constants. Our default option set it as a zero vector.\n\n_ iteration is the number of prior samples.\n\nτ::scalar is a maturity for calculating the constant part in the term premium.\nIf τ is empty, the function does not sampling the prior distribution of the constant part in the term premium.\n\nOutput(2)\n\npriorλₚ, priorTP\n\nsamples from the prior distribution of λₚ \nprior samples of constant part in the τ-month term premium\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.conditional_forecasts-NTuple{7, Any}","page":"API","title":"TermStructureModels.conditional_forecasts","text":"conditional_forecasts(S::Vector, τ, horizon, saved_θ, yields, macros, τₙ; mean_macros::Vector=[], data_scale=1200)\n\nInput\n\nscenarios, a result of the posterior sampler, and data \n\nS[t] = conditioned scenario at time size(yields, 1)+t.\nIf we need an unconditional prediction, S = [].\nIf you are conditionaing a scenario, I assume S = Vector{Scenario}.\nτ is a vector of maturities that term premiums of interest has.\nhorizon: maximum length of the predicted path. It should not be small than length(S).\nsaved_θ: the first output of function posterior_sampler.\nmean_macros::Vector: If you demeaned macro variables, you can input the mean of the macro variables. Then, the output will be generated in terms of the un-demeaned macro variables.\n\nOutput\n\nVector{Forecast}(, iteration)\nt'th rows in predicted yields, predicted factors, and predicted TP are the corresponding predicted value at time size(yields, 1)+t.\nMathematically, it is a posterior samples from future observation|past observation,scenario.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.dcurvature_dτ-Tuple{Any}","page":"API","title":"TermStructureModels.dcurvature_dτ","text":"dcurvature_dτ(τ; κQ)\n\nThis function calculate the first derivative of the curvature factor loading w.r.t. the maturity.\n\nInput\n\nκQ: The decay parameter\nτ: The maturity that the derivative is calculated\n\nOutput\n\nthe first derivative of the curvature factor loading w.r.t. the maturity\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.dimQ-Tuple{}","page":"API","title":"TermStructureModels.dimQ","text":"dimQ()\n\nIt returns the dimension of Q-dynamics.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.erase_nonstationary_param-Tuple{Any}","page":"API","title":"TermStructureModels.erase_nonstationary_param","text":"erase_nonstationary_param(saved_θ)\n\nIt filters out posterior samples that implies an unit root VAR system. Only stationary posterior samples remain.\n\nInput\n\nsaved_θ is the first output of function posterior_sampler.\n\nOutput(2):\n\nstationary samples, acceptance rate(%)\n\nThe second output indicates how many posterior samples remain.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.fitted_YieldCurve-Tuple{Any, Vector{LatentSpace}}","page":"API","title":"TermStructureModels.fitted_YieldCurve","text":"fitted_YieldCurve(τ0, saved_Xθ::Vector{LatentSpace}; data_scale=1200)\n\nIt generates a fitted yield curve.\n\nInput\n\nτ0 is a set of maturities of interest. τ0 does not need to be the same as the one used for the estimation.\nsaved_Xθ is a transformed posterior sample using function latentspace.\n\nOutput\n\nVector{YieldCurve}(,# of iteration)\nyields and latents contain initial observations.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.generative-Tuple{Any, Any, Any, Any, Float64}","page":"API","title":"TermStructureModels.generative","text":"generative(T, dP, τₙ, p, noise::Float64; κQ, kQ_infty, KₚXF, GₚXFXF, ΩXFXF, data_scale=1200)\n\nThis function generate a simulation data given parameters. Note that all parameters are the things in the latent factor state space (that is, parameters in struct LatentSpace). There is some differences in notations because it is hard to express mathcal letters in VScode. So, mathcal{F} in my paper is expressed in F in the VScode. And, \"F\" in my paper is expressed as XF.\n\nInput:\n\nnoise = variance of the measurement errors\n\nOutput(3)\n\nyields, latents, macros\n\nyields = Matrix{Float64}(obs,T,length(τₙ))\nlatents = Matrix{Float64}(obs,T,dimQ())\nmacros = Matrix{Float64}(obs,T,dP - dimQ())\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.ineff_factor-Tuple{Any}","page":"API","title":"TermStructureModels.ineff_factor","text":"ineff_factor(saved_θ)\n\nIt returns inefficiency factors of each parameter\n\nInput\n\nVector{Parameter} from posterior_sampler\n\nOutput\n\nEstimated inefficiency factors are in Tuple(κQ, kQ_infty, γ, Σₒ, σ²FF, ϕ). For example, if you want to load an inefficiency factor of ϕ, you can use Output.ϕ.\nIf fix_const_PC1==true in your optimized struct Hyperparameter, Output.ϕ[1,1] can be weird. So you should ignore it.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.isstationary-Tuple{Any}","page":"API","title":"TermStructureModels.isstationary","text":"isstationary(GₚFF)\n\nIt checks whether a reduced VAR matrix has unit roots. If there is at least one unit root, return is false.\n\nInput\n\nGₚFF should not include intercepts. Also, GₚFF is dP by dP*p matrix that the coefficient at lag 1 comes first, and the lag p slope matrix comes last. \n\nOutput\n\nboolean\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.latentspace-Tuple{Any, Any, Any}","page":"API","title":"TermStructureModels.latentspace","text":"latentspace(saved_θ, yields, τₙ; data_scale=1200)\n\nThis function translates the principal components state space into the latent factor state space. \n\nInput\n\ndata_scale::scalar: In typical affine term structure model, theoretical yields are in decimal and not annualized. But, for convenience(public data usually contains annualized percentage yields) and numerical stability, we sometimes want to scale up yields, so want to use (data_scale*theoretical yields) as variable yields. In this case, you can use data_scale option. For example, we can set data_scale = 1200 and use annualized percentage monthly yields as yields.\n\nOutput\n\nVector{LatentSpace}(, iteration)\nlatent factors contain initial observations.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.log_marginal-Tuple{Any, Any, Any, Hyperparameter, Any, Any}","page":"API","title":"TermStructureModels.log_marginal","text":"log_marginal(PCs, macros, ρ, tuned::Hyperparameter, τₙ, Wₚ; ψ=[], ψ0=[], medium_τ, medium_τ_pr, fix_const_PC1)\n\nThis file calculates a value of our marginal likelihood. Only the transition equation is used to calculate it. \n\nInput\n\ntuned is a point where the marginal likelihood is evaluated. \t\nψ0 and ψ are multiplied with prior variances of coefficients of the intercept and lagged regressors in the orthogonalized transition equation. They are used for imposing zero prior variances. A empty default value means that you do not use this function. [ψ0 ψ][i,j] is corresponds to ϕ[i,j]. \n\nOutput\n\nthe log marginal likelihood of the VAR system.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.loglik_mea-Tuple{Any, Any}","page":"API","title":"TermStructureModels.loglik_mea","text":"loglik_mea(yields, τₙ; κQ, kQ_infty, ϕ, σ²FF, Σₒ, data_scale)\n\nThis function generate a log likelihood of the measurement equation.\n\nOutput\n\nthe measurement equation part of the log likelihood\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.loglik_tran-Tuple{Any, Any}","page":"API","title":"TermStructureModels.loglik_tran","text":"loglik_tran(PCs, macros; ϕ, σ²FF)\n\nIt calculate log likelihood of the transition equation. \n\nOutput\n\nlog likelihood of the transition equation.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.posterior_sampler-Tuple{Any, Any, Any, Any, Any, Hyperparameter}","page":"API","title":"TermStructureModels.posterior_sampler","text":"posterior_sampler(yields, macros, τₙ, ρ, iteration, tuned::Hyperparameter; medium_τ=collect(30:2:48), init_param=[], ψ=[], ψ0=[], γ_bar=[], medium_τ_pr=[], μkQ_infty=0, σkQ_infty=0.1, fix_const_PC1=false, data_scale=1200)\n\nThis is a posterior distribution sampler.\n\nInput\n\niteration: # of posterior samples\ntuned: optimized hyperparameters used during estimation\ninit_param: starting point of the sampler. It should be a type of Parameter.\n\nOutput(2)\n\nVector{Parameter}(posterior, iteration), acceptance rate of the MH algorithm\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.prior_κQ-Tuple{Any, Any}","page":"API","title":"TermStructureModels.prior_κQ","text":"prior_κQ(medium_τ, pr)\n\nThe function derive the maximizer decay parameter κQ that maximize the curvature factor loading at each candidate medium-term maturity. And then, it impose a discrete prior distribution on the maximizers with a prior probability vector pr.\n\nInput\n\nmedium_τ::Vector(candidate medium maturities, # of candidates)\npr::Vector(probability, # of candidates)\n\nOutput\n\ndiscrete prior distribution that has a support of the maximizers κQ\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.reducedform-NTuple{4, Any}","page":"API","title":"TermStructureModels.reducedform","text":"reducedform(saved_θ, yields, macros, τₙ; data_scale=1200)\n\nIt converts posterior samples in terms of the reduced form VAR parameters.\n\nInput\n\nsaved_θ is the first output of function posterior_sampler.\n\nOutput\n\nPosterior samples in terms of struct ReducedForm\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.scenario_analysis-Tuple{Vector{T} where T, Any, Any, Any, Any, Any, Any}","page":"API","title":"TermStructureModels.scenario_analysis","text":"scenario_analysis(S::Vector, τ, horizon, saved_θ, yields, macros, τₙ; mean_macros::Vector=[], data_scale=1200)\n\nInput\n\nscenarios, a result of the posterior sampler, and data \n\nS[t] = conditioned scenario at time size(yields, 1)+t.\nSet S = [] if you need an unconditional prediction. \nIf you are conditionaing a scenario, I assume S = Vector{Scenario}.\nτ is a vector of maturities that term premiums of interest has.\nhorizon: maximum length of the predicted path. It should not be small than length(S).\nsaved_θ: the first output of function posterior_sampler.\nmean_macros::Vector: If you demeaned macro variables, you can input the mean of the macro variables. Then, the output will be generated in terms of the un-demeaned macro variables.\n\nOutput\n\nVector{Forecast}(, iteration)\nt'th rows in predicted yields, predicted factors, and predicted TP are the corresponding predicted value at time size(yields, 1)+t.\nMathematically, it is a posterior distribution of E[future obs|past obs, scenario, parameters].\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.term_premium-NTuple{5, Any}","page":"API","title":"TermStructureModels.term_premium","text":"term_premium(τ, τₙ, saved_θ, yields, macros; data_scale=1200)\n\nThis function generates posterior samples of the term premiums.\n\nInput\n\nmaturity of interest τ for Calculating TP\nsaved_θ from function posterior_sampler\n\nOutput\n\nVector{TermPremium}(, iteration)\nOutputs exclude initial observations.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.tuning_hyperparameter-NTuple{4, Any}","page":"API","title":"TermStructureModels.tuning_hyperparameter","text":"tuning_hyperparameter(yields, macros, τₙ, ρ; populationsize=50, maxiter=10_000, medium_τ=collect(30:2:48), upper_q=[1 1; 1 1; 10 10; 100 100], μkQ_infty=0, σkQ_infty=0.1, upper_ν0=[], μϕ_const=[], fix_const_PC1=false, upper_p=18, μϕ_const_PC1=[], data_scale=1200, medium_τ_pr=[], init_ν0=[])\n\nIt optimizes our hyperparameters by maximizing the marginal likelhood of the transition equation. Our optimizer is a differential evolutionary algorithm that utilizes bimodal movements in the eigen-space(Wang, Li, Huang, and Li, 2014) and the trivial geography(Spector and Klein, 2006).\n\nInput\n\nWhen we compare marginal likelihoods between models, the data for the dependent variable should be the same across the models. To achieve that, we set a period of dependent variable based on upperp. For example, if upperp = 3, yields[4:end,:] and macros[4:end,:] are the data for our dependent variable. yields[1:3,:] and macros[1:3,:] are used for setting initial observations for all lags.\npopulationsize and maxiter is a option for the optimizer.\nThe lower bounds for q and ν0 are 0 and dP+2. \nThe upper bounds for q, ν0 and VAR lag can be set by upper_q, upper_ν0, upper_p.\nOur default option for upper_ν0 is the time-series length of the data.\nIf you use our default option for μϕ_const,\nμϕ_const[dQ+1:end] is a zero vector.\nμϕ_const[1:dQ] is calibrated to make a prior mean of λₚ a zero vector.\nAfter step 2, μϕ_const[1] is replaced with μϕ_const_PC1 if it is not empty.\nμϕ_const = Matrix(your prior, dP, upper_p) \nμϕ_const[:,i] is a prior mean for the VAR(i) constant. Therefore μϕconst is a matrix only in this function. In other functions, `μϕconst` is a vector for the orthogonalized VAR system with your selected lag.\nWhen fix_const_PC1==true, the first element in a constant term in our orthogonalized VAR is fixed to its prior mean during the posterior sampling.\ndata_scale::scalar: In typical affine term structure model, theoretical yields are in decimal and not annualized. But, for convenience(public data usually contains annualized percentage yields) and numerical stability, we sometimes want to scale up yields, so want to use (data_scale*theoretical yields) as variable yields. In this case, you can use data_scale option. For example, we can set data_scale = 1200 and use annualized percentage monthly yields as yields.\n\nOutput(2)\n\noptimized Hyperparameter, optimization result\n\nBe careful that we minimized the negative log marginal likelihood, so the second output is about the minimization problem.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.ϕ_2_ϕ₀_C-Tuple{}","page":"API","title":"TermStructureModels.ϕ_2_ϕ₀_C","text":"ϕ_2_ϕ₀_C(; ϕ)\n\nIt divide ϕ into the lagged regressor part and the contemporaneous regerssor part.\n\nOutput(3)\n\nϕ0, C = C0 + I, C0\n\nϕ0: coefficients for the lagged regressors\nC: coefficients for the dependent variables when all contemporaneous variables are in the LHS of the orthogonalized equations. Therefore, the diagonals of C is ones. Note that since the contemporaneous variables get negative signs when they are at the RHS, the signs of C do not change whether they are at the RHS or LHS. \n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.ϕ_σ²FF_2_ΩFF-Tuple{}","page":"API","title":"TermStructureModels.ϕ_σ²FF_2_ΩFF","text":"ϕ_σ²FF_2_ΩFF(; ϕ, σ²FF)\n\nIt construct ΩFF from statistical parameters.\n\nOutput\n\nΩFF\n\n\n\n\n\n","category":"method"},{"location":"api/#Internal-Functions","page":"API","title":"Internal Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [TermStructureModels]\nPublic = false","category":"page"},{"location":"api/#TermStructureModels.Aₓ-Tuple{Any, Any}","page":"API","title":"TermStructureModels.Aₓ","text":"Aₓ(aτ_, τₙ)\n\nInput\n\naτ_ is an output of function aτ.\n\nOutput\n\nAₓ\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.Aₚ-NTuple{4, Any}","page":"API","title":"TermStructureModels.Aₚ","text":"Aₚ(Aₓ_, Bₓ_, T0P_, Wₒ)\n\nInput\n\nAₓ_, Bₓ_, and T0P_ are outputs of function Aₓ, Bₓ, and T0P, respectively.\n\nOutput\n\nAₚ\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.Bₓ-Tuple{Any, Any}","page":"API","title":"TermStructureModels.Bₓ","text":"Bₓ(bτ_, τₙ)\n\nInput\n\nbτ_ is an output of function bτ.\n\nOutput\n\nBₓ\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.Bₚ-Tuple{Any, Any, Any}","page":"API","title":"TermStructureModels.Bₚ","text":"Bₚ(Bₓ_, T1X_, Wₒ)\n\nInput\n\nBₓ_ and T1X_ are outputs of function Bₓ and T1X, respectively.\n\nOutput\n\nBₚ\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.Kϕ-NTuple{4, Any}","page":"API","title":"TermStructureModels.Kϕ","text":"Kϕ(i, V, Xϕ, dP)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.Minnesota-Tuple{Any, Any, Any}","page":"API","title":"TermStructureModels.Minnesota","text":"Minnesota(l, i, j; q, ν0, Ω0)\n\nIt return unscaled prior variance of the Minnesota prior.\n\nInput\n\nlag l, dependent variable i, regressor j in the VAR(p)\nq[:,1] and q[:,2] are [own, cross, lag, intercept] shrikages for the first dQ and remaining dP-dQ equations, respectively.\nν0(d.f.), Ω0(scale): Inverse-Wishart prior for the error-covariance matrix of VAR(p).\n\nOutput\n\nMinnesota part in the prior variance\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.NIG_NIG-NTuple{6, Any}","page":"API","title":"TermStructureModels.NIG_NIG","text":"NIG_NIG(y, X, β₀, B₀, α₀, δ₀)\n\nNormal-InverseGamma-Normal-InverseGamma update\n\nprior: β|σ² ~ MvNormal(β₀,σ²B₀), σ² ~ InverseGamma(α₀,δ₀)\nlikelihood: y|β,σ² = Xβ + MvNormal(zeros(T,1),σ²I(T))\n\nOutput(2)\n\nβ, σ²\n\nposterior sample\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.PCs_2_latents-Tuple{Any, Any}","page":"API","title":"TermStructureModels.PCs_2_latents","text":"PCs_2_latents(yields, τₙ; κQ, kQ_infty, KₚF, GₚFF, ΩFF, data_scale)\n\nNotation XF is for the latent factor space and notation F is for the PC state space.\n\nInput\n\ndata_scale::scalar: In typical affine term structure model, theoretical yields are in decimal and not annualized. But, for convenience(public data usually contains annualized percentage yields) and numerical stability, we sometimes want to scale up yields, so want to use (data_scale*theoretical yields) as variable yields. In this case, you can use data_scale option. For example, we can set data_scale = 1200 and use annualized percentage monthly yields as yields.\n\nOutput(6)\n\nlatent, κQ, kQ_infty, KₚXF, GₚXFXF, ΩXFXF\n\nlatent factors contain initial observations.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.S-Tuple{Any}","page":"API","title":"TermStructureModels.S","text":"S(i; Ω0)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.S_hat-NTuple{6, Any}","page":"API","title":"TermStructureModels.S_hat","text":"S_hat(i, m, V, yϕ, Xϕ, dP; Ω0)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.T0P-NTuple{4, Any}","page":"API","title":"TermStructureModels.T0P","text":"T0P(T1X_, Aₓ_, Wₚ, c)\n\nInput\n\nT1X_ and Aₓ_ are outputs of function T1X and Aₓ, respectively. c is a sample mean of PCs.\n\nOutput\n\nT0P\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.T1X-Tuple{Any, Any}","page":"API","title":"TermStructureModels.T1X","text":"T1X(Bₓ_, Wₚ)\n\nInput\n\nBₓ_ if an output of function Bₓ.\n\nOutput\n\nT1X\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels._conditional_forecasts-NTuple{6, Any}","page":"API","title":"TermStructureModels._conditional_forecasts","text":"_conditional_forecasts(S, τ, horizon, yields, macros, τₙ; κQ, kQ_infty, ϕ, σ²FF, Σₒ, mean_macros, data_scale)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels._scenario_analysis-NTuple{6, Any}","page":"API","title":"TermStructureModels._scenario_analysis","text":"_scenario_analysis(S, τ, horizon, yields, macros, τₙ; κQ, kQ_infty, ϕ, σ²FF, Σₒ, mean_macros, data_scale)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels._scenario_analysis_unconditional-NTuple{5, Any}","page":"API","title":"TermStructureModels._scenario_analysis_unconditional","text":"_scenario_analysis_unconditional(τ, horizon, yields, macros, τₙ; κQ, kQ_infty, ϕ, σ²FF, Σₒ, mean_macros, data_scale)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels._termPremium-NTuple{6, Any}","page":"API","title":"TermStructureModels._termPremium","text":"_termPremium(τ, PCs, macros, bτ_, T0P_, T1X_; κQ, kQ_infty, KₚF, GₚFF, ΩPP, data_scale)\n\nThis function calculates a term premium for maturity τ. \n\nInput\n\ndata_scale::scalar = In typical affine term structure model, theoretical yields are in decimal and not annualized. But, for convenience(public data usually contains annualized percentage yields) and numerical stability, we sometimes want to scale up yields, so want to use (data_scale*theoretical yields) as variable yields. In this case, you can use data_scale option. For example, we can set data_scale = 1200 and use annualized percentage monthly yields as yields.\n\nOutput(4)\n\nTP, timevarying_TP, const_TP, jensen\n\nTP: term premium of maturity τ\ntimevarying_TP: contributions of each [PCs macros] on TP at each time t (row: time, col: variable)\nconst_TP: Constant part of TP\njensen: Jensen's Ineqaulity part in TP\nOutput excludes the time period for the initial observations.  \n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels._unconditional_forecasts-NTuple{5, Any}","page":"API","title":"TermStructureModels._unconditional_forecasts","text":"_unconditional_forecasts(τ, horizon, yields, macros, τₙ; κQ, kQ_infty, ϕ, σ²FF, Σₒ, mean_macros, data_scale)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.aτ-NTuple{4, Any}","page":"API","title":"TermStructureModels.aτ","text":"aτ(N, bτ_, τₙ, Wₚ; kQ_infty, ΩPP, data_scale)\naτ(N, bτ_; kQ_infty, ΩXX, data_scale)\n\nThe function has two methods(multiple dispatch). \n\nInput\n\nWhen Wₚ ∈ arguments: It calculates aτ using ΩPP. \nOtherwise: It calculates aτ using ΩXX = ΩXFXF[1:dQ, 1:dQ], so parameters are in the latent factor space. So, we do not need Wₚ.\nbτ_ is an output of function bτ.\ndata_scale::scalar: In typical affine term structure model, theoretical yields are in decimal and not annualized. But, for convenience(public data usually contains annualized percentage yields) and numerical stability, we sometimes want to scale up yields, so want to use (data_scale*theoretical yields) as variable yields. In this case, you can use data_scale option. For example, we can set data_scale = 1200 and use annualized percentage monthly yields as yields.\n\nOutput\n\nVector(Float64)(aτ,N)\nFor i'th maturity, Output[i] is the corresponding aτ.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.bτ-Tuple{Any}","page":"API","title":"TermStructureModels.bτ","text":"bτ(N; κQ)\n\nIt solves the difference equation for bτ.\n\nOutput\n\nfor maturity i, bτ[:, i] is a vector of factor loadings.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.jensens_inequality-Tuple{Any, Any, Any}","page":"API","title":"TermStructureModels.jensens_inequality","text":"jensens_inequality(τ, bτ_, T1X_; ΩPP, data_scale)\n\nThis function evaluate the Jensen's Ineqaulity term. All term is invariant with respect to the data_scale, except for this Jensen's inequality term. So, we need to scale down the term by data_scale.\n\nOutput\n\nJensen's Ineqaulity term for aτ of maturity τ.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.post_kQ_infty-NTuple{4, Any}","page":"API","title":"TermStructureModels.post_kQ_infty","text":"post_kQ_infty(μkQ_infty, σkQ_infty, yields, τₙ; κQ, ϕ, σ²FF, Σₒ, data_scale)\n\nOutput\n\nFull conditional posterior distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.post_Σₒ-Tuple{Any, Any}","page":"API","title":"TermStructureModels.post_Σₒ","text":"post_Σₒ(yields, τₙ; κQ, kQ_infty, ΩPP, γ, p, data_scale)\n\nPosterior sampler for the measurement errors\n\nOutput\n\nVector{Dist}(IG, N-dQ)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.post_γ-Tuple{}","page":"API","title":"TermStructureModels.post_γ","text":"post_γ(; γ_bar, Σₒ)\n\nPosterior sampler for the population measurement error\n\nOutput\n\nVector{Dist}(Gamma,length(Σₒ))\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.post_κQ-Tuple{Any, Any, Any}","page":"API","title":"TermStructureModels.post_κQ","text":"post_κQ(yields, prior_κQ_, τₙ; kQ_infty, ϕ, σ²FF, Σₒ, data_scale)\n\nInput\n\nprior_κQ_ is a output of function prior_κQ.\n\nOutput\n\nFull conditional posterior distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.post_ϕ_σ²FF-NTuple{6, Any}","page":"API","title":"TermStructureModels.post_ϕ_σ²FF","text":"post_ϕ_σ²FF(yields, macros, μϕ_const, ρ, prior_κQ_, τₙ; ϕ, ψ, ψ0, σ²FF, q, ν0, Ω0, κQ, kQ_infty, Σₒ, fix_const_PC1, data_scale)\n\nFull-conditional posterior sampler for ϕ and σ²FF \n\nInput\n\nprior_κQ_ is a output of function prior_κQ.\nWhen fix_const_PC1==true, the first element in a constant term in our orthogonalized VAR is fixed to its prior mean during the posterior sampling.\n\nOutput(3)\n\nϕ, σ²FF, isaccept=Vector{Bool}(undef, dQ)\n\nIt gives a posterior sample.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.prior_C-Tuple{}","page":"API","title":"TermStructureModels.prior_C","text":"prior_C(; Ω0::Vector)\n\nWe translate the Inverse-Wishart prior to a series of the Normal-Inverse-Gamma (NIG) prior distributions. If the dimension is dₚ, there are dₚ NIG prior distributions. This function generates Normal priors.  \n\nOutput:\n\nunscaled prior of C in the LDLt decomposition, ΩFF = inv(C)*diagm(σ²FF)*inv(C)'\n\nImportant note\n\nprior variance for C[i,:] = σ²FF[i]*variance of output[i,:]\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.prior_γ-Tuple{Any, Any}","page":"API","title":"TermStructureModels.prior_γ","text":"prior_γ(yields, p)\n\nThere is a hierarchcal structure in the measurement equation. The prior means of the measurement errors are γ[i] and each γ[i] follows Gamma(1,γ_bar) distribution. This function decides γ_bar empirically. OLS is used to estimate the measurement equation and then a variance of residuals is calculated for each maturities. An inverse of the average residual variances is set to γ_bar.\n\nOutput\n\nhyperparameter γ_bar\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.prior_σ²FF-Tuple{}","page":"API","title":"TermStructureModels.prior_σ²FF","text":"prior_σ²FF(; ν0, Ω0::Vector)\n\nWe translate the Inverse-Wishart prior to a series of the Normal-Inverse-Gamma (NIG) prior distributions. If the dimension is dₚ, there are dₚ NIG prior distributions. This function generates Inverse-Gamma priors.  \n\nOutput:\n\nprior of σ²FF in the LDLt decomposition,ΩFF = inv(C)*diagm(σ²FF)*inv(C)'\nEach element in the output follows Inverse-Gamma priors.\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.prior_ϕ0-Tuple{Any, Vector{T} where T, Any, Any, Any}","page":"API","title":"TermStructureModels.prior_ϕ0","text":"prior_ϕ0(μϕ_const, ρ::Vector, prior_κQ_, τₙ, Wₚ; ψ0, ψ, q, ν0, Ω0, fix_const_PC1)\n\nThis part derives the prior distribution for coefficients of the lagged regressors in the orthogonalized VAR. \n\nInput\n\nprior_κQ_ is a output of function prior_κQ.\nWhen fix_const_PC1==true, the first element in a constant term in our orthogonalized VAR is fixed to its prior mean during the posterior sampling.\n\nOutput\n\nNormal prior distributions on the slope coefficient of lagged variables and intercepts in the orthogonalized equation. \nOutput[:,1] for intercepts, Output[:,1+1:1+dP] for the first lag, Output[:,1+dP+1:1+2*dP] for the second lag, and so on.\n\nImportant note\n\nprior variance for ϕ[i,:] = σ²FF[i]*var(output[i,:])\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.yϕ_Xϕ-Tuple{Any, Any, Any}","page":"API","title":"TermStructureModels.yϕ_Xϕ","text":"yϕ_Xϕ(PCs, macros, p)\n\nThis function generate the dependent variable and the corresponding regressors in the orthogonalized transition equation.\n\nOutput(4)\n\nyϕ, Xϕ = [ones(T - p) Xϕ_lag Xϕ_contemporaneous], [ones(T - p) Xϕ_lag], Xϕ_contemporaneous\n\nyϕ and Xϕ is a full matrix. For i'th equation, the dependent variable is yϕ[:,i] and the regressor is Xϕ. \nXϕ is same to all orthogonalized transtion equations. The orthogonalized equations are different in terms of contemporaneous regressors. Therefore, the corresponding regressors in Xϕ should be excluded. The form of parameter ϕ do that task by setting the coefficients of the excluded regressors to zeros. In particular, for last dP by dP block in ϕ, the diagonals and the upper diagonal elements should be zero. \n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.ν-Tuple{Any, Any}","page":"API","title":"TermStructureModels.ν","text":"ν(i, dP; ν0)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.ϕ_hat-NTuple{6, Any}","page":"API","title":"TermStructureModels.ϕ_hat","text":"ϕ_hat(i, m, V, yϕ, Xϕ, dP)\n\n\n\n\n\n","category":"method"},{"location":"api/#TermStructureModels.ϕ_σ²FF_2_ΩPP-Tuple{}","page":"API","title":"TermStructureModels.ϕ_σ²FF_2_ΩPP","text":"ϕ_σ²FF_2_ΩPP(; ϕ, σ²FF)\n\nIt construct ΩPP from statistical parameters.\n\nOutput\n\nΩPP\n\n\n\n\n\n","category":"method"},{"location":"#TermStructureModels.jl","page":"Home","title":"TermStructureModels.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"NOTE. As I am currently in the job market, the completion of the documentation has been delayed. I will finish the work in February. Thanks.","category":"page"},{"location":"","page":"Home","title":"Home","text":"No-Arbitrage Term Structure Models are theoretical government bond models where the bond price satisfies the no-arbitrage condition. It is a Gaussian model because all shocks follow Normal distributions. GDTSM.jl is a package for estimating the GDTSM. I follow the three-factor GDTSM of Joslin, Singleton, and Zhu (JSZ, 2011).","category":"page"},{"location":"","page":"Home","title":"Home","text":"The main features of the package are","category":"page"},{"location":"","page":"Home","title":"Home","text":"Bayesian Estimation with automatically tuned hyper-parameters in a data-driven way (including VAR(p) lag selection)\nYield curve interpolation and fitting\nDecomposition of a bond yield into the expectation hypothesis component and the term premium component\nThe capability of accommodating unspanned macro risks\nScenario Analyses and unconditional forecasts under the large-scale VAR framework to inspect interactions between bond yields and the macroeconomy","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you have any suggestions, please feel free to ask me by raising issues.","category":"page"},{"location":"#Prerequisites","page":"Home","title":"Prerequisites","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Since we use two R packages (GIGrvg, glasso), users have to install R language. If you already have experience using RCall.jl, you just need to install the two R Packages. If it is the first time using RCall.jl, follow the below steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Install R on your computer from the internet.\nIn R, run the below command and copy the home address.","category":"page"},{"location":"","page":"Home","title":"Home","text":"R.home()","category":"page"},{"location":"","page":"Home","title":"Home","text":"In R, run the below code to install the packages.","category":"page"},{"location":"","page":"Home","title":"Home","text":"install.packages(\"GIGrvg\")\ninstall.packages(\"glasso\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"In Juila, run","category":"page"},{"location":"","page":"Home","title":"Home","text":"ENV[\"R_HOME\"]=\"\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"In Juila, run","category":"page"},{"location":"","page":"Home","title":"Home","text":"ENV[\"PATH\"]=\"...the address in step 2...\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"In Juila, run","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"RCall\")","category":"page"},{"location":"#Model","page":"Home","title":"Model","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We follow the JSZ form, but with the restriction that Q-eigenvalues are [1, exp( - kappa^mathbbQ), exp( - kappa^mathbbQ)]. In this case, kappa^mathbbQ is statistically equivalent to the decay parameter of the Dynamic Nelson-Siegel model (Diebold and Li, 2006). That is, our restricted JSZ model is statistically equivalent to the AFNS model (Christensen, Diebold, and Rudebusch, 2011).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Despite the AFNS restriction, our theoretical model sustains the JSZ form. The latent factors in our JSZ model are transformed into the principal components. And then, we estimate the model with the transformed state space as the JSZ did. One major difference between JSZ and ours is that we use the Bayesian methodology. For details, see our paper.","category":"page"},{"location":"#Estimation","page":"Home","title":"Estimation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Note that all yield data should be annual percentage data (i.e. yield data = 1200 times theoretical yield in the model).","category":"page"},{"location":"#Step1.-Tuning-hyper-parameters","page":"Home","title":"Step1. Tuning hyper-parameters","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We have four hyper-parameters, p, q, nu_0, and Omega_0.","category":"page"},{"location":"","page":"Home","title":"Home","text":"p\n(Float64): lag of the VAR(p) in mathbbP -measure\nq\n(Vector) = [ q_1; q_2; q_3; q_4]: Minnesota prior\nPrior variances of slopes propto q_1/ lag^q_3 (for own lagged variables) or q_2/ lag^q_3 (for cross lagged variables)\nPrior variances of intercepts propto q_4\nnu_0\n(Float64), Omega_0(Vector): Error covariance of VAR(p) backsim InverseWishart(nu_0, Omega_0)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We have additional two hyper-parameters that can be decided more objectively.","category":"page"},{"location":"","page":"Home","title":"Home","text":"rho\n(Vector): ρ is a vector that has a size of size(macros,2). If i'th variable in macros is a growth(or level) variable, rho[i] = 0(or approx 1) should be set.\nmedium_τ(Vector): Candidate maturities where the curvature factor loading is maximized. The default value is 12, 18, 24, 30, 36, 42, 48, 54, 60. When you estimate quarterly or annual data, this value should be modified.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Struct \"HyperParameter(p, q, nu_0, Omega_0)\" contains hyper-parameter values. We have a function \"tuning_hyperparameter\" that generates struct \"HyperParameter\" in a data-driven way (Chan, 2022).","category":"page"},{"location":"","page":"Home","title":"Home","text":"tuned = tuning_hyperparameter(yields, macros, ρ)","category":"page"},{"location":"","page":"Home","title":"Home","text":"When using the function, T by N matrix \"yields\" and T by M matrix \"macros\" should contain initial observations (t = 0, -1, -2, cdots).","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can maximize the model selection criterion (marginal likelihood) directly if you want to. The objective function is","category":"page"},{"location":"","page":"Home","title":"Home","text":"log_marginal(PCs, macros, ρ, tuned::HyperParameter; medium_τ = 12 * [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5])","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here, the objective is maximized over \"tuned\", and initial observations also should be included. \"PCs\" are the first, second, and third principal components of yields. We have a function for the principal component analysis.","category":"page"},{"location":"","page":"Home","title":"Home","text":"PCs, OCs, Wₚ, Wₒ = PCA(yields, p; rescaling=true)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function uses eigenVectors of cov(yields[p+1:end,:]) to transform yields[1:end, :] to PCs. When rescaling = true, standard deviations of all PCs are normalized to an average of standard deviations of yields. Here, PCs and OCs are the first three and remaining principal components, respectively. Also, PCs[t, :] = Wₚ times yields[t, :] and OCs[t, :] = Wₒ times yields[t, :] hold.","category":"page"},{"location":"#Step-2.-sampling-the-posterior-distribution-of-GDTSM","page":"Home","title":"Step 2. sampling the posterior distribution of GDTSM","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"saved_θ, acceptPr_C_σ²FF, acceptPr_ηψ = posterior_sampler(yields, macros, τₙ, ρ, iteration, tuned::HyperParameter; sparsity=false, medium_τ=12 * [1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5], init_param=[])","category":"page"},{"location":"","page":"Home","title":"Home","text":"When using the function, T by N matrix \"yields\" and T by M matrix \"macros\" should contain initial observations (t = 0, -1, -2, cdots). τₙ is a vector that contains observed maturities of \"yields\". \"Iteration\" is the number of Gibbs sampling samples. Function \"posteriorsampler\" generate a vector of struct \"Parameter\"s that contains posterior samples. The second and third outputs say an MH acceptance probability of { \\phi{i} σ²_FFi: i = 1, cdots, d_mathbbQ } and ηψ, respectively.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When \"sparsity = true\", we introduce additional Normal-Gamma(NG) priors on the intercepts and slopes while maintaining the Minnesota prior (Chan, 2021). The NG prior leads to the Generalized Inverse Gaussian posterior distribution. To sample this posterior, we use R package \"GIGrvg\" (Hörmann and Leydold, 2014).","category":"page"},{"location":"","page":"Home","title":"Home","text":"We provide a default starting point for the sampler. However, if you want to set it, use keyward \"init_param\" that should be struct \"Parameter\".","category":"page"},{"location":"#Inference","page":"Home","title":"Inference","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To call posterior samples of objects in structs (\"Parameter\", \"ReducedForm\" \"LatentSpace\", \"YieldCurve\", \"TermPremium\", and \"Forecast\"), use [:name]. For example, for output \"saved_θ\" of function \"posterior sampler\",","category":"page"},{"location":"","page":"Home","title":"Home","text":"samples = saved_θ[:κQ]\nsamples[i] # i'th posterior sample of κQ","category":"page"},{"location":"","page":"Home","title":"Home","text":"The variable names in structs \"Parameter\", \"ReducedForm\", and \"LatentSpace\" represent","category":"page"},{"location":"","page":"Home","title":"Home","text":"κQ: kappa^mathbbQ,\nkQinfty: k^{\\mathbb{Q}}{\\infty}$,\nϕ: { phi_i; i = 1, cdots, d_mathbbP },\nσ²FF: { sigma^2_mathcalFFi ; i = 1, cdots, d_mathbbP },\nηψ: eta_psi,\nψ: d_mathbbP by pcdot d_mathbbP Matrix, [[ psi_1ij ] cdots [ psi_pij ] ]\nψ0: { psi_0i : i=1, cdots, d_mathbbP }\nΣₒ: Sigma_mathcalO\nγ: { gamma_i : i=1, cdots, N - d_mathbbQ }\nKₚF: K^mathbbP_mathcalF\nGₚFF: [ G^P_mathcalFF1 cdots G^P_mathcalFFp ]\nΩFF: Omega_mathcalFF\nλP: lambda_mathcalP\nΛPF: [[Lambda_mathcalPP1, Lambda_mathcalPM1] cdots [ Lambda_mathcalPPp, Lambda_mathcalPMp]]\nKₚXF: K^mathbbP_F\nGₚXFXF: [ G^P_FF1 cdots G^P_FFp ]\nΩXFXF: Omega_FF","category":"page"},{"location":"","page":"Home","title":"Home","text":"in our paper. Parameters in \"ReducedForm\" and \"LatentSpace\" can be deduced by using functions \"reducedform\" and \"latentspace\", respectively. \"ReducedForm\" contains the reduced form VAR(p) parameters. \"LatentSpace\" contains parameters when our model is expressed in terms of latent factor X_t","category":"page"},{"location":"","page":"Home","title":"Home","text":"We support mean(), var(), std(), median(), quantile() in Statistics.jl. So, for example, when we need a posterior mean,","category":"page"},{"location":"","page":"Home","title":"Home","text":"mean(saved_θ)[:kQ_infty]","category":"page"},{"location":"","page":"Home","title":"Home","text":"gives the corresponding posterior mean of kQ_infty. All functions, [:name], cdots, quantile(), can be run on six structs, which are \"Parameter\", \"ReducedForm\" \"LatentSpace\", \"YieldCurve\", \"TermPremium\", and \"Forecast\".","category":"page"},{"location":"#Structs-in-the-packages","page":"Home","title":"Structs in the packages","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To see names of objects in the structs, run, for example,","category":"page"},{"location":"","page":"Home","title":"Home","text":"help?>YieldCurve","category":"page"},{"location":"","page":"Home","title":"Home","text":"We have eight structs, which are HyperParameter, Parameter, ReducedForm, LatentSpace, YieldCurve, TermPremium, Scenario, and Forecast. It also provides details of the structs.","category":"page"},{"location":"#Introducing-a-sparsity-on-error-precision-matrix","page":"Home","title":"Introducing a sparsity on error precision matrix","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"sparse_θ, trace_λ, trace_sparsity = sparse_prec(saved_θ::Vector{Parameter}, yields, macros, τₙ)","category":"page"},{"location":"","page":"Home","title":"Home","text":"It introduces a sparsity on the error precision matrix of VAR(p) P-dynamics using Freidman, Hastie, and Tibshirani (2008) and Hauzenberger, Huber, and Onorante (2021). We use R-package \"glasso\" to implement it. Specifically, the additionally introduced lasso penalty makes some small elements in the precision to zero.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here, the data should contain initial observations. τₙ is a vector that contains observed maturities of \"yields\". \"savedθ\" is an output of function \"posterior sampler\". For the outputs, \"sparseθ\" is also a vector of struct \"Parameter\" but has sparse precision matrices. \"traceλ\" and \"tracesparsity\" contain the used optimal penalty parameter and the number of non-zero elements of the precision.","category":"page"},{"location":"#Yield-curve-interpolation","page":"Home","title":"Yield curve interpolation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"fitted = fitted_YieldCurve(τ0, saved_Xθ::Vector{LatentSpace})","category":"page"},{"location":"","page":"Home","title":"Home","text":"To derive the fitted yield curve, you first derive \"saved_Xθ\" from function \"latentspace\". τ0 is a vector that contains maturities of interest. The output is Vector{\"YieldCurve\"}.","category":"page"},{"location":"#Term-premium","page":"Home","title":"Term premium","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"saved_TP = term_premium(τ, τₙ, saved_θ::Vector{Parameter}, yields, macros)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function calculates term premium estimates of maturity τ (months). Here, τ does not need to be the one in τₙ. \"τₙ\", \"yields\", and \"macros\" are the things that were inputs of function \"posterior sampler\". \"savedθ\" is the output of function \"posterior sampler\". Output \"savedTP\" is Vector{TermPremium}.","category":"page"},{"location":"#Scenario-Analysis-and-unconditional-forecasts","page":"Home","title":"Scenario Analysis and unconditional forecasts","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"prediction = scenario_sampler(S::Scenario, τ, horizon, saved_θ, yields, macros, τₙ)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The function generates (un)conditional forecasts using our model. We use the Kalman filter to make conditional filtered forecasts (Bańbura, Giannone, and Lenza, 2015), and then we use Kim and Nelson (1999) to make smoothed posterior samples of the conditional forecasts. \"S\" is a conditioned scenario, and yields, risk factors, and a term premium of maturity \"τ\" are forecasted. \"horizon\" is a forecasting horizon. \"τₙ\", \"yields\", and \"macros\" are the things that were inputs of function \"posterior sampler\". \"saved_θ\" is an output of function \"posterior sampler\". The output is Vector{Forecast}.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Struct Scenario has two elements, \"combinations\" and \"values\". Meaning of the struct can be found by help? command. Examples of making struct \"Scenario\" are as follows.","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Case 1. Unconditional Forecasts\nS = []\n\n# Case 2. Scenario with one conditioned variable and time length 2\ncomb = zeros(1, size([yields macros], 2))\ncomb[1, 1] = 1.0 # one month yield is selected as a conditioned variable\nvalues = [3.0] # Scenario: one month yield at time T+1 is 3.0\nS = Scenario(combinations=comb, values=values)\n\n# Case 3. Scenario with two conditioned combinations and time length 3\ncomb = zeros(2, size([yields macros], 2), 3)\nvalues = zeros(2, 3)\nfor t in 1:3 # for simplicity, we just assume the same scenario for time = T+1, T+2, T+3. Users can freely assume different scenarios for each time T+t.\n  comb[1, 1, t] = 1.0 # one month yield is selected as a conditioned variable in the first combination\n  comb[2, 20, t] = 0.5\n  comb[2, 21, t] = 0.5 # the average of 20th and 21st observables is selected as a second conditioned combination\n  values[1,t] = 3.0 # one month yield at time T+t is 3.0\n  values[2,t] = 0.0 # the average value is zero.\nend\nS = Scenario(combinations=comb, values=values)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Here, both \"combinations\" and \"values\" should be type Array{Float64}. Also, \"horizon\" should not be smaller than size(values, 2).","category":"page"}]
}
